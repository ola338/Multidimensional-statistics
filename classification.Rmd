---
title: "R Notebook"
output: html_notebook
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(MASS)
library(ISLR)
library(class)
library(nnet)
library(tidyverse)
library(caret)
```

```{r}
student <- read.csv(file = 'student/student-mat.csv', sep=";")
names(student)
dim(student)
head(student)
```

```{r}
student$sex[student$sex == "M"] <- 1
student$sex[student$sex == "F"] <- 0
student$sex <- as.integer(student$sex)

dir_logistic <- list()
dir_logistic$fit <- glm(sex ~ . , data = student)
summary(dir_logistic$fit)
```
## Kilka parametrów okazało się być skorelowanych z płcią uczniów:

# -   studytime - ilość czasu poświęcanego na naukę

# -   higher - chęć zdobycia wyższego doświadczenia

# -   activities - uczestnictwo w dodatkowych zajęciach

# -   absences - ilość nieobecności w szkole

# -   freetime - ilość wolnego czasu



## Podział na zbiór testowy i treningowy
```{r}
smp_size <- floor(0.75 * nrow(student))
set.seed(123)
train_ind <- sample(seq_len(nrow(student)), size = smp_size)

train <- student[train_ind, ]
test <- student[-train_ind, ]
```

## Regresja logistyczna

# Dopasowywujemy model regresji logistycznej żeby przewidzieć płeć na podstawie najbardziej zależnych zmiennych
```{r}
dir_logistic <- list()
dir_logistic$fit <- glm(sex ~ studytime + higher +Mjob + activities+ freetime + absences + Dalc + Walc, data = train)
```

# Wyliczamy prawdopodobieństwa i wyświetlamy dla 6 pierwszych rekodów
```{r}
dir_logistic$probs <- predict(dir_logistic$fit, test, type = "response")
head(dir_logistic$probs)
```

```{r}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, "M", "F")
```

##  Macierz pomyłek 
# Female: 0,  Male: 1
```{r}
dir_logistic$cm <- table(dir_logistic$predicted, test$sex)
dir_logistic$cm
```

# Proporcja błędów --> model lepiej radzi sobie z klasyfikacją mężczyzn
```{r}
(dir_logistic$cm[1, 2] + dir_logistic$cm[2, 1]) / sum(dir_logistic$cm)
mean(dir_logistic$predicted != "M")
mean(dir_logistic$predicted != "F")
```

# Dokładność
```{r}
(dir_logistic$cm[1, 1] + dir_logistic$cm[2, 2]) / sum(dir_logistic$cm)
```

# Regresja logistyczna tylko na podstawie 3 najbardziej znaczących cech
```{r}
dir_logistic <- list()
dir_logistic$fit <- glm(sex ~ studytime + higher + Mjob, data = train)
```

# Wyliczamy prawdopodobieństwa i wyświetlamy dla 6 pierwszych rekodów
```{r}
dir_logistic$probs <- predict(dir_logistic$fit, test, type = "response")
head(dir_logistic$probs)
```

```{r}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, "M", "F")
```

##  Macierz pomyłek 
# Female: 0,  Male: 1
```{r}
dir_logistic$cm <- table(dir_logistic$predicted, test$sex)
dir_logistic$cm
```

# Proporcja błędów  --> model lepiej radzi sobie z klasyfikacją mężczyzn
```{r}
(dir_logistic$cm[1, 2] + dir_logistic$cm[2, 1]) / sum(dir_logistic$cm)
mean(dir_logistic$predicted != "M")
mean(dir_logistic$predicted != "F")
```

# Dokładność
```{r}
(dir_logistic$cm[1, 1] + dir_logistic$cm[2, 2]) / sum(dir_logistic$cm)
```


# Regresja logistyczna tylko na podstawie 1 najbardziej znaczącej cechy
```{r}
dir_logistic <- list()
dir_logistic$fit <- glm(sex ~ studytime, data = train)
```

# Wyliczamy prawdopodobieństwa 
```{r}
dir_logistic$probs <- predict(dir_logistic$fit, test, type = "response")
head(dir_logistic$probs)
```

```{r}
dir_logistic$predicted <- ifelse(dir_logistic$probs > 0.5, "M", "F")
```

##  Macierz pomyłek 
# Female: 0,  Male: 1
```{r}
dir_logistic$cm <- table(dir_logistic$predicted, test$sex)
dir_logistic$cm
```

# Proporcja błędów 
```{r}
(dir_logistic$cm[1, 2] + dir_logistic$cm[2, 1]) / sum(dir_logistic$cm)
```

# Dokładność
```{r}
(dir_logistic$cm[1, 1] + dir_logistic$cm[2, 2]) / sum(dir_logistic$cm)
```
### PORÓWNANIE WYNIKÓW

# wszystkie predyktory - 0.30
# 3 najbardziej znaczące - 0.26
# 1 najbardziej znaczący - 0.30




## LDA na podstawie 3 najbardziej zależnych zmiennych
```{r}
dir_lda <- list()
dir_lda$fit <- lda(sex ~ studytime + higher + Mjob, data = train)
```

# Wyliczamy predykcje i Macierz pomyłek 
# Female: 0,  Male: 1
```{r}
dir_lda$predicted <- predict(dir_lda$fit, test)
cm = table(dir_lda$predicted$class, test$sex)
cm
```


# Proporcja błędów  
```{r}
(cm[1, 2] + cm[2, 1]) / sum(cm)
```

# Dokładność  --> dokładnie takie same wyniki jak dla regresji logistycznej
```{r}
(cm[1, 1] + cm[2, 2]) / sum(cm)
```


### QDA - kwadratowy dyskryminator na podstawie 3 najbardziej zależnych zmiennych
```{r}
dir_qda <- list()
dir_qda$fit <- qda(sex ~ studytime + higher + Mjob, data = train)
```

# Wyliczamy predykcje i Macierz pomyłek 
# Female: 0,  Male: 1
```{r}
dir_qda$predicted <- predict(dir_qda$fit, test)
cm = table(dir_qda$predicted$class, test$sex)
cm
```

# Proporcja błędów  
```{r}
(cm[1, 2] + cm[2, 1]) / sum(cm)
```

# Dokładność  -->  niższa dokłądność od regresji logistycznej oraz LDA
```{r}
(cm[1, 1] + cm[2, 2]) / sum(cm)
```


## kNN

```{r}
train_set <- train[c("studytime")]
test_set <- test[c("studytime")]
dir_knn_1 <- knn(train = train_set, test = test_set, cl = train$sex, k = 7)
table(dir_knn_1, test$sex)
```
# Obliczenie błędu
```{r}
mean(dir_knn_1 != test$sex)
```
## proporcja błędów dla k = [1, 10]  --> brak zmian
```{r }
errors = rep()

for (i in 1:10) {
  knn <- knn(train = train_set, test = test_set, cl = train$sex, k = 7)
  error <- mean(knn != test$sex)
  errors <- append(errors, error)
}
errors
```

### PORÓWNANIE WYNIKÓW

# regresja logistyczna - 0.26
# LDA - 0.26
# QDA - 0.32
# KNN - 0.30
